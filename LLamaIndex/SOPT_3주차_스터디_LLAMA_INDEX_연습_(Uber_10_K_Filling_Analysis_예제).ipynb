{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SOPT 3주차 스터디 중 Fine-tuning 학습을 위한 LLamaIndex 연습입니다.\n",
        "## Author: Sigrid Jin (twitter.com/sigridjin_eth)\n",
        "### 링크 모음\n",
        "* https://github.com/jerryjliu/llama_index\n",
        "* https://gpt-index.readthedocs.io/\n",
        "* https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d\n",
        "* https://github.com/jerryjliu/llama_index/blob/main/examples/chatbot/Chatbot_SEC.ipynb\n",
        "* 0.5.0 버전 이하의 collab 실습은 다음 링크를 참고하시기 바랍니다. https://colab.research.google.com/drive/1uL1TdMbR4kqa0Ksrd_Of_jWSxWt1ia7o?usp=sharing\n",
        "* https://gpt-index.readthedocs.io/en/latest/guides/tutorials/building_a_chatbot.html"
      ],
      "metadata": {
        "id": "LGl8y-KZaRwk"
      },
      "id": "LGl8y-KZaRwk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlamaIndex란 무엇인가?\n",
        "LlamaIndex is an interface between your data and LLM’s; it offers the toolkit for you to setup a query interface around your data for any downstream task, whether it’s question-answering, summarization, or more.\n",
        "\n",
        "## 이번 튜토리얼에서 다룰 내용은...\n",
        "* How to build a context augmented chatbot.\n",
        "* We use Langchain for the underlying Agent/Chatbot abstractions, and we use LlamaIndex for the data retrieval/lookup/querying.\n",
        "* The result is a chatbot agent that has access to a rich set of “data interface” Tools that LlamaIndex provides to answer queries over your data."
      ],
      "metadata": {
        "id": "ACyaL-DVzXFq"
      },
      "id": "ACyaL-DVzXFq"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index # 0.6.0.alpha3 버전을 기준으로 실습합니다.\n",
        "# pip install --upgrade llama-index==0.6.0.alpha3\n",
        "!pip install pdfminer.six # pip install pdfminer가 아닙니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VzpGEMJsauHh",
        "outputId": "a547de20-9271-4bd3-e127-36ba9c07ea1f"
      },
      "id": "VzpGEMJsauHh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.6.0a3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.7)\n",
            "Requirement already satisfied: langchain==0.0.142 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.0.142)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.27.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (1.4.48)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (4.0.2)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (0.1.21)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142->llama-index) (2.27.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama-index) (1.3.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache>=0.1.7->langchain==0.0.142->llama-index) (5.3.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.142->llama-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.142->llama-index) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.142->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.142->llama-index) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.142->llama-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (40.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download files\n",
        "!mkdir data\n",
        "!wget https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1 -O data/UBER.zip\n",
        "!unzip data/UBER.zip -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC4R6nkCp91d",
        "outputId": "15efd329-96d1-4ac0-da97-fb352a33bf36"
      },
      "id": "YC4R6nkCp91d",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2023-05-02 04:27:45--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\n",
            "--2023-05-02 04:27:46--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com/cd/0/get/B7T9mGW-wE-m2O1KPvAarYQ-L6FuTwNeMZptd1tH_i0DvLGthb8f-0PP20pB4bNO2fE8F1CH3UBn2-YgiyOLp_jdJbc47JasLun2m8_oyXk0I6q2cltAS5lpbwapmvonPlsrPzekGy7RbiK7wxbfZnbQFBCNfTXHj4KLVWNEKJKZ9w/file?dl=1# [following]\n",
            "--2023-05-02 04:27:46--  https://uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com/cd/0/get/B7T9mGW-wE-m2O1KPvAarYQ-L6FuTwNeMZptd1tH_i0DvLGthb8f-0PP20pB4bNO2fE8F1CH3UBn2-YgiyOLp_jdJbc47JasLun2m8_oyXk0I6q2cltAS5lpbwapmvonPlsrPzekGy7RbiK7wxbfZnbQFBCNfTXHj4KLVWNEKJKZ9w/file?dl=1\n",
            "Resolving uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com (uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com (uc31d876bcefc9c06ed1a4e69cc8.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1820227 (1.7M) [application/binary]\n",
            "Saving to: ‘data/UBER.zip’\n",
            "\n",
            "data/UBER.zip       100%[===================>]   1.74M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-05-02 04:27:46 (23.5 MB/s) - ‘data/UBER.zip’ saved [1820227/1820227]\n",
            "\n",
            "Archive:  data/UBER.zip\n",
            "replace data/UBER/UBER_2021.html? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set text wrapping\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "CuHeyb224pI2"
      },
      "id": "CuHeyb224pI2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-내꺼야\"\n",
        "!pip show llama-index"
      ],
      "metadata": {
        "id": "QaFX6KfIz-Zn",
        "outputId": "0e6375c9-793f-4f2a-87c8-1dcb800a14c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "id": "QaFX6KfIz-Zn",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: llama-index\n",
            "Version: 0.6.0a3\n",
            "Summary: Interface between LLMs and your data.\n",
            "Home-page: https://github.com/jerryjliu/gpt_index\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: dataclasses-json, langchain, numpy, openai, pandas, tenacity, tiktoken\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61",
      "metadata": {
        "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61",
        "outputId": "267e84d2-1efb-44a0-a0e7-85de232b9d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from llama_index import download_loader, GPTSimpleVectorIndex\n",
        "from llama_index import download_loader, GPTVectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a",
      "metadata": {
        "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a"
      },
      "source": [
        "### Unstructured.io Reader를 이용한 Unstructured Data 가져오기\n",
        "\n",
        "Unstructured.io HTML 파서를 이용한다\n",
        "* 참고: LlamaHub https://llamahub.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3",
      "metadata": {
        "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3",
        "outputId": "aa1a7651-262c-4898-ae3a-eef725bfd71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "29084a11-f3da-428d-ae17-27b85a365e84",
      "metadata": {
        "id": "29084a11-f3da-428d-ae17-27b85a365e84",
        "outputId": "09cdca8c-923a-4a2c-d409-f7d677bdba52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "loader = UnstructuredReader()\n",
        "doc_set = {}\n",
        "all_docs = []\n",
        "years = [2022, 2021, 2020, 2019]\n",
        "for year in years:\n",
        "    year_docs = loader.load_data(file=Path(f'./data/UBER/UBER_{year}.html'), split_documents=False)\n",
        "    # insert year metadata into each year\n",
        "    for d in year_docs:\n",
        "        d.extra_info = {\"year\": year}\n",
        "    doc_set[year] = year_docs\n",
        "    all_docs.extend(year_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Service Context"
      ],
      "metadata": {
        "id": "DzuCgTq3Vs53"
      },
      "id": "DzuCgTq3Vs53"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "\n",
        "service_context = ServiceContext.from_defaults(chunk_size_limit=512)"
      ],
      "metadata": {
        "id": "1vdCAXCoVvs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3873e876-7e00-4fa7-93c0-ac1a116b0132"
      },
      "id": "1vdCAXCoVvs0",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d",
      "metadata": {
        "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d"
      },
      "source": [
        "### 연도별 SEC 재무제표를 Vector Index로 변환\n",
        "\n",
        "2019년부터 2022년까지 SEC 각 연도별 재무제표를 Vector Index로 변환한다. 그 이후에 Vector Index 를 하나의 Vector Store로 합친 전역 Index를 하나 만든다.\n",
        "\n",
        "We first setup a vector index for each year. Each vector index allows us to ask questions about the 10-K filing of a given year.\n",
        "\n",
        "We build each index and save it to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
      "metadata": {
        "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
        "outputId": "927d2510-d949-4748-c301-376701674034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # initialize simple vector indices + global vector index\n",
        "# # NOTE: don't run this cell if the indices are already loaded! \n",
        "# index_set = {}\n",
        "# for year in years:\n",
        "#     cur_index = GPTSimpleVectorIndex.from_documents(doc_set[year], service_context=service_context)\n",
        "#     index_set[year] = cur_index\n",
        "#     cur_index.save_to_disk(f'index_{year}.json')\n",
        "\n",
        "service_context = ServiceContext.from_defaults(chunk_size_limit=512)\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    cur_index = GPTVectorStoreIndex.from_documents(\n",
        "        doc_set[year], \n",
        "        service_context=service_context,\n",
        "        storage_context=storage_context,\n",
        "    )\n",
        "    index_set[year] = cur_index\n",
        "    storage_context.persist(persist_dir=f'./storage/{year}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34",
      "metadata": {
        "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "07fcc291-eb8f-45c5-d401-6758995d6773"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# To load an index from disk, do the following...\n",
        "# Load indices from disk\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=f'./storage/{year}')\n",
        "    cur_index = load_index_from_storage(storage_context=storage_context)\n",
        "    index_set[year] = cur_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 개의 Indexes를 묶는 (즉, HTML 파일을 묶는) 합성 그래프 만들기\n",
        "* Since we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.\n",
        "\n",
        "* To address this, we compose a “graph” which consists of a list index defined over the 4 vector indices. Querying this graph would first retrieve information from each vector index, and combine information together via the list index."
      ],
      "metadata": {
        "id": "SN2sVgp_z0ID"
      },
      "id": "SN2sVgp_z0ID"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import GPTListIndex, LLMPredictor, ServiceContext, load_graph_from_storage\n",
        "from langchain import OpenAI\n",
        "from llama_index.indices.composability import ComposableGraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uYljwKbMxrIh",
        "outputId": "bfbca52e-b17c-4a09-db4e-b70e093cf0b0"
      },
      "id": "uYljwKbMxrIh",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describe each index to help traversal of composed graph\n",
        "index_summaries = [f\"UBER 10-k Filing for {year} fiscal year\" for year in years]\n",
        "\n",
        "# define an LLMPredictor set number of output tokens\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, max_tokens=512))\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "# define a list index over the vector indices\n",
        "# allows us to synthesize information across each index\n",
        "graph = ComposableGraph.from_indices(\n",
        "    GPTListIndex,\n",
        "    [index_set[y] for y in years], \n",
        "    index_summaries=index_summaries,\n",
        "    service_context=service_context,\n",
        "    storage_context = storage_context,\n",
        ")\n",
        "root_id = graph.root_id\n",
        "\n",
        "# [optional] save to disk\n",
        "storage_context.persist(persist_dir=f'./storage/root')\n",
        "\n",
        "# [optional] load from disk, so you don't need to build graph from scratch\n",
        "graph = load_graph_from_storage(\n",
        "    root_id=root_id, \n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8MFGqTCUxt3C",
        "outputId": "8859444b-6133-424b-d934-880a59c0e6bb"
      },
      "id": "8MFGqTCUxt3C",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the Chatbot Agent (Langchain 활용)\n",
        "* 외부 챗봇과 인터랙션을 하는 것에서의 인터페이스를 Langchain으로 사용하고 Langchain을 LlamaIndex랑 연결한다.\n",
        "* We use Langchain to setup the outer chatbot agent, which has access to a set of Tools. LlamaIndex provides some wrappers around indices and graphs so that they can be easily used within a Tool interface.\n",
        "* We want to define a separate Tool for each index (corresponding to a given year), as well as the graph. We can define all tools under a central LlamaToolkit interface.\n",
        "* Below, we define a IndexToolConfig for our graph. Note that we also import a DecomposeQueryTransform module for use within each vector index within the graph - this allows us to “decompose” the overall query into a query that can be answered from each subindex."
      ],
      "metadata": {
        "id": "eVbT35jXqhJA"
      },
      "id": "eVbT35jXqhJA"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e46dd052-ab34-4974-b696-16ff217970e0",
      "metadata": {
        "id": "e46dd052-ab34-4974-b696-16ff217970e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bc8ee93e-a889-4e41-ed46-ff6ddc798126"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from llama_index.langchain_helpers.agents import LlamaToolkit, create_llama_chat_agent, IndexToolConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that we also import a DecomposeQueryTransform module for use within each vector index\n",
        "# within the graph - this allows us to “decompose” the overall query\n",
        "# into a query that can be answered from each subindex.\n",
        "\n",
        "# 그러니까 DecomposeQueryTransform 를 사용하면 전체 query를 subquery로 잘라서\n",
        "# subindex가 각각 대답할 수 있는 형태로 변환한다는 뜻임\n",
        "# define a decompose transform\n",
        "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
        "decompose_transform = DecomposeQueryTransform(\n",
        "    llm_predictor, verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WpJGJ0A2rul_",
        "outputId": "09de1dc0-da28-4d5c-fc6f-46f3df934c45"
      },
      "id": "WpJGJ0A2rul_",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define custom retrievers\n",
        "# !pip install --upgrade llama-index==0.6.0.alpha3\n",
        "from llama_index.query_engine.transform_query_engine import TransformQueryEngine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4AFJYm6ssLWe",
        "outputId": "7fa790ed-89d9-43d8-a14f-c3cb0d177d96"
      },
      "id": "4AFJYm6ssLWe",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_query_engines = {}\n",
        "for index in index_set.values():\n",
        "    query_engine = index.as_query_engine()\n",
        "    query_engine = TransformQueryEngine(\n",
        "        query_engine,\n",
        "        query_transform=decompose_transform,\n",
        "        transform_extra_info={'index_summary': index.index_struct.summary},\n",
        "    )\n",
        "    custom_query_engines[index.index_id] = query_engine\n",
        "custom_query_engines[graph.root_id] = graph.root_index.as_query_engine(\n",
        "    response_mode='tree_summarize',\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# tool config\n",
        "graph_config = IndexToolConfig(\n",
        "    query_engine=query_engine,\n",
        "    name=f\"Graph Index\",\n",
        "    description=\"useful for when you want to answer queries that require analyzing multiple SEC 10-K documents for Uber.\",\n",
        "    tool_kwargs={\"return_direct\": True}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lmSyt0Omsejl",
        "outputId": "52ac2659-09f7-449b-fbb0-405336f653bc"
      },
      "id": "lmSyt0Omsejl",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Besides the GraphToolConfig object, we also define an IndexToolConfig corresponding to each index."
      ],
      "metadata": {
        "id": "Ec4LNHOt0LgL"
      },
      "id": "Ec4LNHOt0LgL"
    },
    {
      "cell_type": "code",
      "source": [
        "# define toolkit\n",
        "index_configs = []\n",
        "for y in range(2019, 2023):\n",
        "    query_engine = index_set[y].as_query_engine(\n",
        "        similarity_top_k=3,\n",
        "    )\n",
        "    tool_config = IndexToolConfig(\n",
        "        query_engine=query_engine, \n",
        "        name=f\"Vector Index {y}\",\n",
        "        description=f\"useful for when you want to answer queries about the {y} SEC 10-K for Uber\",\n",
        "        tool_kwargs={\"return_direct\": True}\n",
        "    )\n",
        "    index_configs.append(tool_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CclzdrCuxZQi",
        "outputId": "96749117-1769-466b-d101-d90063e20976"
      },
      "id": "CclzdrCuxZQi",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Finally, we combine these configs with our LlamaToolkit."
      ],
      "metadata": {
        "id": "wW7giHBA0SCu"
      },
      "id": "wW7giHBA0SCu"
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = LlamaToolkit(\n",
        "    index_configs=index_configs + [graph_config],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "efBAW9lax7tA",
        "outputId": "e8ea619a-9207-4a9b-bea2-72104c1236d5"
      },
      "id": "efBAW9lax7tA",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Finally, we call create_llama_chat_agent to create our Langchain chatbot agent, which has access to the 5 Tools we defined above."
      ],
      "metadata": {
        "id": "RnYCO7P40VGB"
      },
      "id": "RnYCO7P40VGB"
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm=OpenAI(temperature=0)\n",
        "agent_chain = create_llama_chat_agent(\n",
        "    toolkit,\n",
        "    llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vigz-lUhx9YJ",
        "outputId": "e161f4ae-4cf2-4d32-a89a-37564e6b6632"
      },
      "id": "vigz-lUhx9YJ",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Agent"
      ],
      "metadata": {
        "id": "YeFLiUa_yALn"
      },
      "id": "YeFLiUa_yALn"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Hi I am Sigrid!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "l9yphuzHx-cL",
        "outputId": "5fdeb2ca-feff-4167-a327-1856b1da87e3"
      },
      "id": "l9yphuzHx-cL",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: Hi Sigrid, nice to meet you! How can I help you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi Sigrid, nice to meet you! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"What were some of the biggest risk factors in 2020 for Uber?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ZwN8cTlDyCGE",
        "outputId": "d43a8a94-7969-41dc-d979-3a949e1a930c"
      },
      "id": "ZwN8cTlDyCGE",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Vector Index 2020\n",
            "Action Input: Risk Factors\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "The following are some of these risks, any of which could have an adverse effect on our business financial condition, operating results, or prospects:\n",
            "\n",
            "1. The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue to adversely affect parts of our business.\n",
            "\n",
            "2. Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\n",
            "\n",
            "3. The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\n",
            "\n",
            "4. To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\n",
            "\n",
            "5. We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve profitability.\n",
            "\n",
            "6. If we are unable to attract or maintain a critical mass of\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe following are some of these risks, any of which could have an adverse effect on our business financial condition, operating results, or prospects:\\n\\n1. The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue to adversely affect parts of our business.\\n\\n2. Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\\n\\n3. The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\\n\\n4. To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\\n\\n5. We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve profitability.\\n\\n6. If we are unable to attract or maintain a critical mass of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_query_str = (\n",
        "    \"Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\"\n",
        ")\n",
        "agent_chain.run(input=cross_query_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "himbBGuIyF2j",
        "outputId": "141b1011-fd2f-4ec8-dea0-f85381778a37"
      },
      "id": "himbBGuIyF2j",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "AI: Sure, here are the key risk factors for Uber across the years:\n",
            "\n",
            "2019:\n",
            "• The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\n",
            "• We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve profitability.\n",
            "\n",
            "2020:\n",
            "• The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue to adversely affect parts of our business.\n",
            "• Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\n",
            "• To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\n",
            "\n",
            "2021:\n",
            "• The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure, here are the key risk factors for Uber across the years:\\n\\n2019:\\n• The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\\n• We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve profitability.\\n\\n2020:\\n• The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue to adversely affect parts of our business.\\n• Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\\n• To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\\n\\n2021:\\n• The COVID-19 pandemic and the impact of actions to mitigate the pandemic has adversely affected and may continue'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    text_input = input(\"User: Question is ... \")\n",
        "    response = agent_chain.run(input=text_input)\n",
        "    print(f'Agent: {response}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PfnFB_Y6yNj9",
        "outputId": "4a860614-e9f4-4c3f-9f66-22beddb5cc41"
      },
      "id": "PfnFB_Y6yNj9",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Question is ... What were some of the legal proceedings against Uber in 2022?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAI: In 2022, Uber faced a number of legal proceedings, including:\n",
            "\n",
            "• A class action lawsuit alleging that Uber misclassified its drivers as independent contractors instead of employees.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the California Consumer Privacy Act by collecting and sharing personal information without consent.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Telephone Consumer Protection Act by sending unsolicited text messages.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Americans with Disabilities Act by failing to provide accessible transportation services.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Fair Credit Reporting Act by using background checks to discriminate against certain applicants.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: In 2022, Uber faced a number of legal proceedings, including:\n",
            "\n",
            "• A class action lawsuit alleging that Uber misclassified its drivers as independent contractors instead of employees.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the California Consumer Privacy Act by collecting and sharing personal information without consent.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Telephone Consumer Protection Act by sending unsolicited text messages.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Americans with Disabilities Act by failing to provide accessible transportation services.\n",
            "\n",
            "• A lawsuit alleging that Uber violated the Fair Credit Reporting Act by using background checks to discriminate against certain applicants.\n",
            "User: Question is ... What were some of the CoVID-19 situations against Uber in 2021?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "AI: In 2021, Uber faced a number of COVID-19 related issues, including:\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate compensation for drivers who were unable to work due to the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent: In 2021, Uber faced a number of COVID-19 related issues, including:\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate compensation for drivers who were unable to work due to the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n",
            "\n",
            "• A lawsuit alleging that Uber failed to provide adequate safety measures for its drivers and riders during the pandemic.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-9ab706ebdf6f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: Question is ... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Agent: {response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4xost6cOyTi0"
      },
      "id": "4xost6cOyTi0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gpt_retrieve_venv",
      "language": "python",
      "name": "gpt_retrieve_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}